{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FastAPI + Celery = \u2665","text":"<p> Hello there!</p> <p>Interested in Python FastAPI? Wondering how to execute long-running tasks in the background in Python? You came to the right place!</p> <p>This little website will go through the basics of Poetry, FastAPI and Celery, with some detours here and there.</p> <p>Note</p> <p>I built this website for a talk given at the GDG Fribourg in March 2023. Please keep that in mind: the technologies may have evolved a little. Versions used at the time of writing:</p> <ul> <li>poetry <code>1.3.0</code></li> <li>FastAPI <code>0.95.0</code></li> <li>Celery <code>5.2.7</code></li> </ul> <p>I learned about FastAPI and Celery when confronted with a simple yet interesting use case:</p> <p></p> <p>I had a Jupyter Notebook that connected to a database, ran some heavy processing on the data (using machine learning and everything) and saved aggregated data back to the database. Since notebooks are great for developing, the requirement was to keep using notebooks for development but to be able to trigger the processing from an API call. The notebook should never be executed twice in parallel though: the API should thus return an error if the notebook was already being executed. Note that the notebook would be provided once at deployment time: it won't change during the lifecycle of the app.</p> <p>I was initially planning to use a simple Flask app, but soon got into trouble<sup>1</sup>: how can I (1) run the notebook in a background thread and (2) restrict its execution to one at a time?</p> <p>The solution will be explained on those pages. If you are only interested in the final implementation, have a look at my nb-runner project on GitHub:</p> <p> fastapi-notebook-runner</p> <ol> <li> <p>for the story, I first switched to FastAPI for its   Background Tasks. I thought it would   allow me to avoid Celery. I soon discovered it wasn't enough, as I had no control over the number of tasks.   I thus ended up learning Celery after all. But the switch was still worth it!\u00a0\u21a9</p> </li> </ol>"},{"location":"01-poetry/","title":"Poetry","text":"<p>Before getting started, we need a Python project.</p> <p>poetry is the trendy package manager which superseded setuptools and pyenv in the heart of pythonistas.</p>"},{"location":"01-poetry/#installation","title":"Installation","text":"<p>If you haven't done so, install poetry: https://python-poetry.org/docs/#installation. On a Mac: <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n</code></pre></p> <p>I currently use: <pre><code>poetry --version\nPoetry (version 1.3.0)\n</code></pre></p> <p>The installation will create a new virtualenv especially for poetry somewhere in your system. On a Mac, use <code>cat $(which poetry)</code> and look at the first line. In my case:</p> <ul> <li><code>poetry</code> executable installed in <code>~/.local/bin/poetry</code></li> <li>poetry's virtualenv installed in <code>~/Library/Application Support/pypoetry/venv/</code></li> </ul>"},{"location":"01-poetry/#initializing-a-project","title":"Initializing a project","text":"<p>Once poetry is installed, initializing a new project is as easy as running: <pre><code>mkdir fastapi-celery &amp;&amp; cd fastapi-celery\npoetry init\n</code></pre></p> <p>Follow the prompts. You can already start adding dependencies (<code>fastapi</code>, <code>celery</code>) and dev-dependencies (<code>bandit</code>, <code>black</code>) or choose to do that later.</p> <p>Once you finished with the prompt, have a look at what was generated: <pre><code>cat pyproject.toml\n</code></pre></p>"},{"location":"01-poetry/#adding-dependencies","title":"Adding dependencies","text":"<p>You can add a dependency at any time using: <code>poetry add &lt;package-name&gt;</code>. If the dependency is for development only, use the <code>--group dev</code> flag (or any other group name).</p> <p>You can also edit the <code>pyproject.toml</code> directly and run <code>poetry install</code>.</p> <p>I use <code>poetry add</code> with a name (no version) and then update the <code>pyprojet.toml</code> manually to pin only the minor version (instead of the full version). This means replacing e.g. <code>fastapi = \"^0.93.0\"</code> with <code>fastapi = \"^0.93\"</code> (notice the <code>.0</code> is missing). This way, I can still beneficiate from patch updates by running <code>poetry update</code> at any time. I also often use '*' for dev dependencies.</p> <p>See Dependency specification for more information.</p>"},{"location":"01-poetry/#creating-a-virtualenv","title":"Creating a virtualenv","text":"<p>This only set up the project. Now, we need to create a virtualenv and install those dependencies. Poetry can do this for us using: <pre><code>poetry install\n</code></pre></p> <p>Poetry will automatically create a virtualenv, located in a central place on your system. I will be blunt: I  this; I like to have virtualenvs at the root of each project instead. This ensures all is cleaned up if I delete a project and I can always use <code>source .venv/bin/activate</code> from any repo to have my virtualenv selected.</p> <p>To change poetry's default behavior to something more suited to my tastes, create a <code>poetry.toml</code> at the root of the project with the following: <pre><code>[virtualenvs]\nin-project = true\npath = \".venv\"\n</code></pre></p> <p>Warning</p> <p>If you already ran the install, remove the old virtualenv first (<code>poetry env list</code> + <code>poetry env remove &lt;name&gt;</code>), and run <code>poetry install</code> again.</p>"},{"location":"01-poetry/#and-more","title":"And more","text":"<p>Other nice things about poetry:</p> <ul> <li><code>poetry show --latest</code> will show the current and latest available versions of your dependencies</li> <li><code>poetry env</code> allows you to manage environments: remove, list, info, etc.</li> <li>running <code>poetry install --sync</code> ensures that the locked dependencies in the <code>poetry.lock</code> are the only ones   present in the environment, removing anything that\u2019s not necessary.</li> <li>you can choose to install only certain groups (in addition to main) using <code>poetry install --with dev</code>,    or only a specific group using <code>poetry install --only main</code>.</li> <li>running <code>poetry update</code> will fetch the latest matching versions (according to the <code>pyproject.toml</code> file) and update   the lock file with the new versions. This is equivalent to deleting the <code>poetry.lock</code> file and running <code>install</code> again.</li> <li>you can build the project using <code>poetry build</code>, and publish it to PyPI using <code>poetry publish</code> (given you have set up   you credentials properly)</li> </ul> <p>The documentation is amazing, so I will stop here.</p>"},{"location":"01-poetry/#bonus","title":"BONUS","text":""},{"location":"01-poetry/#formatting-with-black","title":"formatting with black","text":"<p>black is a strict formatter. From their docs:</p> <p>Black is the uncompromising Python code formatter. By using it, you agree to cede control over minutiae of hand-formatting. In return, Black gives you speed, determinism, and freedom from pycodestyle nagging about formatting. You will save time and mental energy for more important matters.</p> <p>To install it: <pre><code>poetry add black='*' --group dev\n</code></pre></p> <p>Now, all you have to do is run: <pre><code>poetry run black fastapi_celery\n</code></pre></p> <p>Note that you can also configure VSCode to use black by default.</p> <p>The default line length is 88. If for some reason you want to change this, you can use: <pre><code>poetry run black --line-length 100 --experimental-string-processing fastapi_celery\n</code></pre></p> <p>The <code>--experimental-string-processing</code> is still under development. Without it, black won't split long strings...</p> <p>To only perform checks (without formatting anyhting, e.g. in CI), use: <pre><code>poetry run black --check fastapi_celery\n</code></pre></p>"},{"location":"01-poetry/#linting-with-ruff","title":"linting with ruff","text":"<p>I just discovered ruff, which is just awesome!</p> <p>It basically replaces all the other tools (except formatting, but it is coming soon) such as:</p> <ul> <li><code>isort</code> - sorts imports</li> <li><code>bandit</code> - finds common security issues</li> <li><code>flake8</code> - linter</li> <li>etc.</li> </ul> <p>Ruff is implemented in Rust and is really (really!) fast. The configuration can be done from the <code>pyproject.toml</code> directly, but the defaults are already quite nice.</p> <p>Full list of available rules here</p> <p>Get started by installing it: <pre><code>poetry add ruff='*' --group dev\n</code></pre></p> <p>Now, run it using: <pre><code># Check only\npoetry run ruff fastapi_celery\n# Automatically fix what can be fixed\npoetry run ruff --fix fastapi_celery\n</code></pre></p> <p>I played a bit with the options, and currently decided to use:</p> <pre><code># in pyproject.toml\n\n[tool.ruff]\nselect = [\n    \"E\",   # pycodestyle error\n    \"W\",   # pycodestyle warning\n    \"F\",   # pyflakes\n    \"A\",   # flakes8-builtins\n    \"COM\", # flakes8-commas\n    \"C4\",  # flake8-comprehensions\n    \"Q\",   # flake8-quotes\n    \"SIM\", # flake8-simplify\n    \"PTH\", # flake8-use-pathlib\n    \"I\",   # isort\n    \"N\",   # pep8 naming\n    \"UP\",  # pyupgrade  \n    \"S\",   # bandit\n]\n</code></pre> <p>Have a look at the docs, it is really good!</p>"},{"location":"02-fastapi/","title":"FastAPI","text":"<p>FastAPI is:</p> <p>a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based  on standard Python type hints.</p> <p>Their documentation is amazing (way better than this one), so please check it out!</p> <p>FastAPI docs</p>"},{"location":"02-fastapi/#about-wsgi-and-asgi","title":"About WSGI and ASGI","text":"<p>It is important to understand that FastAPI is an ASGI Application Framework. It cannot serve anything by itself: it needs an ASGI Server (or a WSGI server with an ASGI worker).</p> <p>WSGI stands for Web Server Gateway Interface, and ASGI for Asynchronous Server Gateway interface. They both specify an interface that sits in between a web server and a Python web application or framework. WSGI has been around for a long time. ASGI is a spiritual successor to WSGI, that is able to handle asynchronous requests and responses.</p> <p>In short, an (A|W)SGI Server is a web server that is able to call python code when it receives an HTTP request. The way it calls this code, and what parameters are passed to the calling function, are all specified in the (A|W)SGI interface specification. It includes information about the request and the environment.</p> <p>It is then the role of the (A|W)SGI Application to build the headers and to return the data as iterable. This is done using the <code>start_response</code> call. Here is a simple WSGI application (source):</p> <pre><code>def simple_app(environ, start_response):\n    status = '200 OK'\n    response_headers = [('Content-type','text/plain')]\n    # Actually start sending data back to the server\n    start_response('200 OK', response_headers)\n    return ['Hello world!\\n']\n</code></pre> <p>This <code>simple_app</code> can then be passed to a server and be served as is.</p> <p>Of course, apps are usually way more complex, with routing, proxies and complex logic involved. This is why we use (A|W)SGI Application Frameworks such as FastAPI. Those frameworks have a single entry point (that is called by the server), and lots of conveniences to abstract the complexities of constructing responses, handling errors, doing redirects, determining which code to execute, etc.</p> <p></p> <p>To actually run a FastAPI app, we thus need an ASGI server (or a WSGI server with an ASGI-compatible worker). In development, we can use uvicorn - a minimalist server with a single process.</p> <p>While a single process is enough for testing, it is not suitable for production. The most common production setup for FastAPI is gunicorn with uvicorn workers, sitting behind a reverse proxy such as Nginx.</p> <p>Why the reverse proxy you ask?  Gunicorn is amazing at handling workers and WSGI-specific things, while NGINX is a full-featured HTTP server, able to handle millions of concurrent connections, provide DoD protection, rewrite headers, and serve static resources more effectively. Together, they form the perfect team.</p> <p>See also: The Layered World Of Web Development: Why I Need NGINX And UWSGI To Run A Python App?</p>"},{"location":"02-fastapi/#install-fastapi-uvicorn","title":"Install FastAPI + uvicorn","text":"<p>Anyway, to get started, we only need to install both FastAPI and uvicorn: <pre><code>poetry add fastapi\npoetry add 'uvicorn[standard]'\n</code></pre></p> <p>The uvicorn server can then be launched (with reload!) using: <pre><code>uvicorn package.filename:app_object --reload\n</code></pre></p>"},{"location":"02-fastapi/#getting-started","title":"Getting started","text":"<p>Create a file <code>fastapi_celery/main.py</code> and add:</p> <pre><code>from fastapi import FastAPI\nfrom typing import Dict \n\napp = FastAPI() # &lt;- the ASGI entrypoint\n\n@app.get('/')\ndef index() -&gt; Dict:\n    return {'greating': 'hello'}\n</code></pre> <p>Run uvicorn with reload: <pre><code>uvicorn fastapi_celery.main:app --reload\n</code></pre></p> <p>Note</p> <p>It is also possible to run uvicorn directly from the python file, to allow for debugging: <pre><code>import uvicorn\n\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre></p> <p>If you use <code>reload=True</code>, however, you have to pass the <code>app</code> as an import string, in our case <code>celery_fastapi.main:app</code>.</p> <p>and try it using: <pre><code>curl http://localhost:8000/\n</code></pre></p> <p>Congrats! You have successfully coded a REST API.</p> <p>Now, open the following in your browser: <code>http://localhost:8000/docs</code>. FastAPI comes built-in with a Swagger UI the OpenApi specification for us based on type hints.</p> <p>Want more? FastAPI also comes with a ReDoc documentation: <code>http://localhost:8000/redoc</code>!</p> <p>In short, you get those endpoints for free:</p> <ul> <li><code>/docs</code> \u2192 Interactive API docs (Swagger UI)</li> <li><code>/redoc</code> \u2192 Alternative API docs (ReDoc documentation)</li> <li><code>/openapi.json</code> \u2192 OpenAPI spec (JSON document)</li> </ul>"},{"location":"02-fastapi/#a-simple-example","title":"A simple example","text":"<p>Let's imagine we want an endpoint to create a new user. Let's start with the most basic thing, we'll improve later.</p> <pre><code>from fastAPI import FastAPI\nfrom typing import Any\nfrom datetime import datetime\n\napp = FastAPI\n\n@app.get(\"/\")\ndef create_user() -&gt; dict[str, Any]:\n    return {\"id\": 10, \"name\": \"my-username\", \"created_at\": datetime.now()}\n</code></pre> <p>Now, looking at the docs, there is not much detail. Let's make it better!</p>"},{"location":"02-fastapi/#documentation","title":"Documentation","text":"<p>We can easily add some description for the endpoint using either a docstring, or the <code>description</code> parameter on the annotation. The annotation also lets us describe the response type. Both support markdown!</p> <pre><code>@app.get('/', response_description=\"The `new` user\")\ndef create_user() -&gt; dict[str, Any]:\n    \"\"\"\n    Create a new user. *Supports `markdown`!*\n    \"\"\"\n</code></pre> <p>For more documentation options:</p> <ul> <li>Metadata and Docs URLs   for general information,</li> <li>Path Operation Configuration   for endpoint annotations,</li> <li>Declare Request Example Data   for extra schema samples. </li> </ul> <p>FastAPI allows describing pretty much anything, and to customize all the fields that will appear in the OpenAPI spec. From now on, always look at the parameters offered by FastAPI classes .</p>"},{"location":"02-fastapi/#model-class","title":"Model class","text":"<p>The return type being a dictionary, FastAPI cannot give much detail, nor do any validation. Let's change this by using a pydantic model.</p> <p>First, install pydantic: <pre><code>poetry add pydantic\n</code></pre></p> <p>And change the code to:</p> <pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom datetime import datetime\nfrom random import randint\n\napp = FastAPI()\n\n\nclass UserOut(BaseModel):\n    id: int = randint(1, 100)\n    name: str\n    creation_date: datetime = datetime.now()\n\n\n@app.get('/')\ndef create_user() -&gt; UserOut:\n    return UserOut(name=\"lucy\")\n</code></pre> <p>Have a look at the successful response example in the docs. Isn't it great?</p>"},{"location":"02-fastapi/#query-parameters","title":"Query parameters","text":"<p>The name is still hard-coded. Why not use a query parameter instead?</p> <pre><code>@app.get(\"/\")\ndef create_user(name: str) -&gt; UserOut:\n    return UserOut(name=name)\n</code></pre> <p>Since <code>name</code> doesn't have a default, it is marked as required in the interface, and omitting it will throw an error.</p> <p>A name, though usually has more than one letter, right? So let's add some validation. For this, we can use the brand new feature of FastAPI 0.95.0: the support for  <code>typing.Annotated</code>!</p> <pre><code>from fastapi import FastAPI, Query\nfrom typing import Annotated\n\n# ...\n\n@app.get(\"/\")\ndef create_user(name: Annotated[str, Query(min_length=3)]) -&gt; UserOut:\n    return UserOut(name=name)\n</code></pre> <p><code>Annotated</code> is here to decorate existing types with context-specific data. Its first argument is always the final type, followed by varyadic arguments. Those metadata arguments are then used by other tools, in our case FastAPI.</p> <p>The <code>Query</code> object is a simple decorator offered by FastAPI that allows adding constraints to a query parameter. I will let you dive into the capabilities of <code>Query</code> on your own!</p>"},{"location":"02-fastapi/#path-parameters","title":"Path parameters","text":"<p>Let's say, for some reason, you want the name to become a path parameter. Suffice to change the path in the annotation: <pre><code>@app.get(\"/{name}\")\n</code></pre></p> <p>If you are using simple parameters (<code>name: str</code>), all is fine. If you have some constraints, though, you need to change the <code>Query</code> from the last example with <code>Path</code>. The logic, however, stays the same:</p> <pre><code>@app.get(\"/{name}\")\ndef create_user(name: Annotated[str, Path(min_length=3)]) -&gt; UserOut:\n    return UserOut(name=name)\n</code></pre>"},{"location":"02-fastapi/#body-parameters","title":"Body parameters","text":"<p>Using a get to create a user is ugly. Furthermore, we may want to have more information from the user such as a password. Let's fix this!</p> <pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel, Field\nfrom datetime import datetime\nfrom random import randint\nfrom typing import Annotated\n\napp = FastAPI()\n\n\nclass UserIn(BaseModel):\n    name: Annotated[str, Field(example=\"my-username\", min_length=3, regex=\"^[a-z-]+$\")]\n    password: Annotated[str, Field(example=\"secret\", min_length=5)]\n\n\nclass UserOut(BaseModel):\n    id: int = randint(1, 100)\n    name: str\n    creation_date: datetime = datetime.now()\n\n\n@app.post(\"/\")\ndef create_user(user: UserIn) -&gt; UserOut:\n    # return user &lt;- would work as well... Try it!\n    return UserOut(**user.dict())\n</code></pre> <p>As you can see, we can use <code>Field</code> on the properties of a pydantic model as we do with <code>Query</code> and <code>Path</code>. Most of the properties are the same!</p> <p>The type hints are enough for FastAPI to provide validation, proper documentation, and IDE support.</p> <p>More interestingly, FastAPI/pydantic takes care of the \"views\". What do I mean by that? Try returning the input user directly (<code>return user</code>). We would expect to see <code>username</code> and <code>password</code> in the results, right? No! FastAPI ensures that what is returned matches the response model. Any extra properties are gone. There is no way the password will show up in the response. This allows for a flexible and elegant class hierarchy.</p> <p>Even cooler, we can fine-tune what is returned using <code>response_model_exclude_none</code> or <code>response_model_exclude_unset</code> in the <code>@app.post()</code> annotation. If set to true, <code>None</code> values or default values won't be returned, respectively.</p> <p>Have a look at all the other options, they are interesting !</p>"},{"location":"02-fastapi/#exceptions","title":"Exceptions","text":"<p>If something goes wrong, simply raise an <code>HTTPException</code> class:</p> <pre><code>from fastapi import FastAPI, HTTPException\n\napp = FastAPI()\n\n@app.get('/error')\ndef error():\n    raise HTTPException(status_code=500, detail=\"Just throwing an internal server error\")\n</code></pre> <p>Just try it: <pre><code>curl http://localhost:8000/error -v\n# &lt; HTTP/1.1 500 Internal Server Error\n# {\"detail\":\"Just throwing an internal server error\"}\n</code></pre></p> <p>Note that the <code>detail</code> can be of any type, not just string. As long as it is JSON-serializable! It is also possible to specify headers.</p>"},{"location":"02-fastapi/#status-code","title":"Status code","text":"<p>Since our method creates a user, it would be better to return a <code>201 - Created</code> instead of a <code>200 - OK</code>. Again, no need to look further, just specify the <code>status_code</code> parameter!</p> <pre><code>@app.post(\"/\", status_code=201)\n</code></pre>"},{"location":"02-fastapi/#other-awesome-features","title":"Other awesome features","text":"<ul> <li>You can add examples and example schemas   that will show up in the UI at all levels. Even better, you can have multiple examples for a body,   and the UI will show you a dropdown you can choose from!</li> <li>FastAPI supports lots of types out-of-the-box!   By supporting, I mean automatic parsing and validation .   The pydantic types are especially useful.   Some examples: <code>EmailStr</code>, <code>Color</code>, <code>FilePath</code>, <code>PastDate</code>, <code>HttpUrl</code>, <code>SecretStr</code> (won't be logged), etc.</li> <li>The body can be composed: if we add multiple models as parameters, FastAPI will merge them together.   For example, declaring:   <pre><code>def some_post(admin_user: User, regular_user: User):\n</code></pre>   will expect an input like this:   <pre><code>{\"admin_user\": {}, \"regular_user\": {}}\n</code></pre>   This avoids the necessity to create extra classes just for composition!</li> <li>Model classes based on pydantic's <code>BaseModel</code>, which has lots of awesome features.   For example, the methods <code>.dict()</code>, <code>.json()</code> and <code>.copy()</code> come out-of-the-box, and   support including, excluding and renaming fields (among other).   More info here.</li> <li>To avoid hard-coding HTTP status codes, use FastAPI's <code>status.HTTP_*</code> constants.</li> <li>The <code>json_encoder()</code>   will convert dict, pydantic models, etc. into valid JSON, a bit like <code>json.dumps</code>. But contrary to the latter,   the result is not a string, but a dictionary with all values compatible with JSON (think of <code>datetime</code> objects).</li> <li>For bigger applications, FastAPI uses <code>APIRouter</code>, which is equivalent to blueprints in Flask.   For more information, read Bigger Applications - Multiple Files.</li> <li>FastAPI has a very powerful but intuitive Dependency Injection system (DI). This can be used to have shared logic,   share database connections, enforce security (e.g. checking the presence of a valid JWT token), etc.   See Dependencies - First Steps.</li> </ul> <p>And so much more!</p>"},{"location":"03-celery/","title":"Celery","text":"<p>Celery is a task queue with focus on real-time processing, while also supporting task scheduling.</p>"},{"location":"03-celery/#what-is-celery","title":"What is Celery","text":"<p>From their documentation:</p> <p>Task queues are used as a mechanism to distribute work across threads or machines. A task queue\u2019s input is a unit of work called a task. Dedicated worker processes constantly monitor task queues for new work to perform.</p> <p>Celery communicates via messages, usually using a broker to mediate between clients and workers. To initiate a task the client adds a message to the queue, the broker then delivers that message to a worker.</p> <p>A Celery system can consist of multiple workers and brokers, giving way to high availability and horizontal scaling. [it] is written in Python, but the protocol can be implemented in any language [(current clients in NodeJS, PHP)].</p> <p></p> <p>In other words, the entities involved in Celery are:</p> <ul> <li>producers: also called clients, they are the ones requesting tasks and doing something with the results.</li> <li>broker: the broker is the message transport, used to send and receive messages between producers and workers.   In other words, they store the task queue. Celery supports a myriad of message brokers,   but currently only two are feature-complete:  Redis and     RabbitMQ.</li> <li>workers: the workers are processes that constantly watch the task queue and execute tasks.</li> <li>result backend: a backend is only necessary when we want to keep track of the tasks' states or retrieve results from tasks.   A result backend is optional but turned on by default,   see Celery without a Results Backend.</li> </ul> <p>See also the diagram in Understanding Celery's architecture</p>"},{"location":"03-celery/#getting-started","title":"Getting started","text":""},{"location":"03-celery/#launch-a-brokerbackend","title":"Launch a broker/backend","text":"<p>First, we need a broker and a backend. We will use Redis, as it is both full-featured and easy to use: <pre><code>poetry add 'celery[redis]'\n</code></pre></p> <p>We can run Redis locally using: <pre><code>docker run --rm --name some-redis -p 6379:6379 redis:latest\n</code></pre></p> <p>Tip</p> <p>To see what happens exactly inside Redis, download and run a Redis GUI such as Another Redis Desktop Manager.</p>"},{"location":"03-celery/#create-a-task","title":"Create a task","text":"<p>Now, let's create a task. We first need to create a Celery instance, which is the entrypoint to Celery: may it be submitting tasks (client), managing workers, getting results, etc. We usually call it the Celery application, or app for short.</p> <pre><code>from celery.app import Celery\n\nredis_url = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n\ncelery_app = Celery(__name__, broker=redis_url, backend=redis_url)\n</code></pre> <p>Now, let's define a dummy task, that will create a file with a timestamp:</p> <pre><code># in file task.py\nfrom celery.app import Celery\nfrom datetime import datetime\nimport os\n\nredis_url = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n\napp = Celery(__name__, broker=redis_url, backend=redis_url)\n\n\n@app.task\ndef dummy_task():\n    folder = \"/tmp/celery\"\n    os.makedirs(folder, exist_ok=True)\n    now = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%s\")\n    with open(f\"{folder}/task-{now}.txt\", \"w\") as f:\n        f.write(\"hello!\")\n</code></pre> <p>To check it works, let's call it directly using the Python REPL (<code>python</code>):</p> <p><pre><code>&gt;&gt;&gt; from fastapi_celery import task\n&gt;&gt;&gt; task.dummy_task()\n</code></pre> This should create the file - we called it directly, so Celery was not involved. To execute this task using Celery, we need to use one of the methods that were added by the decorator (see calling tasks). The most common is <code>delay()</code>, which is a shortcut to <code>apply_async()</code>. Those methods will return an <code>AsyncResult</code>, that can be further used to query the status.</p> <pre><code>&gt;&gt;&gt; t = task.dummy_task.delay()\n&gt;&gt;&gt; t.status\nPENDING\n</code></pre> <p>Why is it pending? Well, we didn't launch any workers, did we? Let's change that.</p>"},{"location":"03-celery/#launch-a-worker","title":"Launch a worker","text":"<p>In another terminal, run: <pre><code>celery --app=fastapi_celery.task.app worker --concurrency=1 --loglevel=DEBUG\n</code></pre></p> <p>Now, try again: <pre><code>&gt;&gt;&gt; t.status\nSUCCESS\n</code></pre></p> <p>To ensure this works, try adding a delay in the task: <code>time.sleep(10)</code>. Don't forget to restart the worker, as the method definition changed! Even better, use <code>watchdog</code> to automatically restart the worker: <pre><code>poetry add watchdog --group=dev\nwatchmedo auto-restart --directory=./fastapi_celery --pattern=task.py -- celery --app=fastapi_celery.task.app worker --concurrency=1 --loglevel=DEBUG\n</code></pre></p>"},{"location":"03-celery/#parameters-and-return-values","title":"Parameters and return values","text":"<p>Now, let's change a bit our dummy task so it receives an argument and returns a result: <pre><code>def dummy_task(name='Bob') -&gt; str:\n    sleep(5)\n    return f'Hello {name}!'\n</code></pre></p> <pre><code>&gt;&gt;&gt; import importlib\n&gt;&gt;&gt; importlib.reload(task)\n&gt;&gt;&gt; t = task.dummy_task.delay('Lucy')\n&gt;&gt;&gt; t.result # empty until success\n&gt;&gt;&gt; t.result\n'Hello Lucy!'\n</code></pre> <p>Try to return a dictionary instead. It should work the same. But what about this?</p> <pre><code>def dummy_task() -&gt; str:\n    return open('/tmp/celery/x.txt', 'w')\n</code></pre> <pre><code>&gt;&gt;&gt; t = task.dummy_task.delay()\n&gt;&gt;&gt; t.status\n'FAILURE'\n&gt;&gt;&gt; t.result\nEncodeError(\"TypeError('Object of type TextIOWrapper is not JSON serializable')\")\nt.successful()\nFalse\n</code></pre> <p>So beware: results must be JSON-serializable (or match the serialization configured in Celery) since the results will be serialized and stored in the results backend.</p>"},{"location":"03-celery/#using-celery-with-fastapi","title":"Using Celery with FastAPI","text":"<p>With those building blocks, we can now bind the two together. We simply import <code>task.py</code> in FastAPI, and call our <code>task.delay()</code> from a REST call. We can return the task ID and its status to the user:</p> <pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom celery.result import AsyncResult\n\nfrom . import task\n\napp = FastAPI()\n\n\nclass TaskOut(BaseModel):\n    id: str\n    status: str\n\n\n@app.get(\"/start\")\ndef start() -&gt; TaskOut:\n    r = task.dummy_task.delay()\n    return _to_task_out(r)\n\n\n@app.get(\"/status\")\ndef status(task_id: str) -&gt; TaskOut:\n    r = task.app.AsyncResult(task_id)\n    return _to_task_out(r)\n\n\ndef _to_task_out(r: AsyncResult) -&gt; TaskOut:\n    return TaskOut(id=r.task_id, status=r.status)\n</code></pre>"},{"location":"03-celery/#restricting-to-one-task-at-a-time","title":"Restricting to one task at a time","text":"<p>Celery doesn't provide an obvious way to limit the number of concurrent tasks. In our use case, we want to have only one task executed at a time. If the user tries to start a task while another is already running, he should get an error.</p> <p>With multithreading/multiprocessing, a common construct is the mutual exclusion (mutex) lock. The thing is, we have multiple processes here, so we need a lock that lives outside the Python process.</p> <p>As we already have Redis, we can use a Redis Lock! But how do we use it?</p> <p>Ideally, we would like to get the lock when we start a task (from the REST endpoint - FastAPI), and release it when the task is finished (from the Celery worker). But a lock should be acquired and released from the same thread... And worse, if our worker fails to release the lock, we are stuck!</p> <p></p> <p>A better way is to use the lock from FastAPI only. We cannot know when the task is finished, but we can query the state of a task given an ID. So let's use the lock to secure the read/write to a Redis key, <code>current_task_id</code>, which holds the ID of the last task!</p> <p></p> <p>So, for the implementation, let's first create a redis lock:</p> <pre><code>from redis import Redis\nfrom redis.lock import Lock as RedisLock\n\nredis_instance = Redis.from_url(task.redis_url)\nlock = RedisLock(redis_instance, name=\"task_id\")\n\nREDIS_TASK_KEY = \"current_task\"\n</code></pre> <p>The <code>/start</code> endpoint now looks like this:</p> <pre><code>@app.get(\"/start\")\ndef start() -&gt; TaskOut:\n    try:\n        if not lock.acquire(blocking_timeout=4):\n            raise HTTPException(status_code=500, detail=\"Could not acquire lock\")\n\n        task_id = redis_instance.get(REDIS_TASK_KEY)\n        if task_id is None or task.app.AsyncResult(task_id).ready():\n            # no task was ever run, or the last task finished already\n            r = task.dummy_task.delay()\n            redis_instance.set(REDIS_TASK_KEY, r.task_id)\n            return _to_task_out(r)\n        else:\n            # the last task is still running!\n            raise HTTPException(\n                status_code=400, detail=\"A task is already being executed\"\n            )\n    finally:\n        lock.release()\n</code></pre> <p>And for the <code>/status</code>, we can now make the <code>task_id</code> query parameter optional:</p> <pre><code>@app.get(\"/status\")\ndef status(task_id: str = None) -&gt; TaskOut:\n    task_id = task_id or redis_instance.get(REDIS_TASK_KEY)\n    if task_id is None:\n        raise HTTPException(\n            status_code=400, detail=f\"Could not determine task {task_id}\"\n        )\n    r = task.app.AsyncResult(task_id)\n    return _to_task_out(r)\n</code></pre> <p>Note</p> <p>This code is far from perfect. For example: what happens if the <code>task_id</code> is incorrect or not known by celery? For <code>/status</code>, we may just get an error. But for <code>/start</code>? The lock may never be released! This is one of many flows, so don't put it in production </p>"},{"location":"03-celery/#canceling-long-running-tasks","title":"Canceling long-running tasks","text":"<p>Maybe we want to cancel the current task. How can we do it?</p> <p>The Celery app gives us access to control, which lets us get statistics, how many workers are running, etc.</p> <pre><code>from . import task\n\n# note: if id is read from redis, use:\n#  task_id = redis_instance.get(...).decode('utf-8')\ntask.app.control.revoke(task_id, terminate=True, signal=\"SIGKILL\")\n</code></pre>"},{"location":"03-celery/#returning-results-and-exceptions","title":"Returning results and exceptions","text":"<p>Simply add a new property to <code>TaskOut</code>:</p> <pre><code>class TaskOut(BaseModel):\n    id: str\n    status: str\n    result: str | None = None\n</code></pre> <p>And modify <code>_to_task_out</code> like this:</p> <pre><code>def _to_task_out(r: AsyncResult) -&gt; TaskOut:\n    return TaskOut(\n        id=r.task_id, \n        status=r.status, \n        result=r.traceback if r.failed() else r.result,\n    )\n</code></pre> <p>You can try to get the traceback by making the task throw an exception or return a value, and then calling: <pre><code>curl http://localhost:8000/start\ncurl http://localhost:8000/status | jq -r '.result'\n</code></pre></p>"},{"location":"04-notebook/","title":"Notebooks","text":"<p>The last piece of the puzzle is to design a task that can execute a Jupyter Notebook.</p>"},{"location":"04-notebook/#a-simple-notebook","title":"A simple notebook","text":"<p>The most basic notebook of all would look like this: <pre><code>{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"ea8edd01\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from os import environ\\n\",\n    \"from time import sleep\\n\",\n    \"\\n\",\n    \"sleep(30)\\n\",\n    \"print(environ.get('SOME_DB_URL'))\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3 (ipykernel)\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.11.0\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 5\n}\n</code></pre></p> <p>It doesn't require any specific dependencies to run except, of course, Jupyter.</p>"},{"location":"04-notebook/#the-fast-and-ugly-way","title":"The fast and ugly way","text":"<p>Since the notebook is not meant to change once the app is started, an easy (but ugly) way is to convert it to a simple Python script (e.g. in CI), and run it using <code>execfile</code>.</p> <p>To convert a Jupyter Notebook provided <code>notebook</code> (or juypter lab) is installed is as easy as calling <code>nbconvert</code>: <pre><code>jupyter nbconvert --to python notebook.ipynb\n</code></pre></p> <p>Then, the task would look like this: <pre><code>@app.task(\"execute_notebook\")\ndef execute_notebook():\n    execfile('notebook.py')\n</code></pre></p> <p>But we could do better, right?</p>"},{"location":"04-notebook/#using-nbconvert-api","title":"Using NbConvert API","text":"<p>If developers use Jupyter Notebook for developing, chances are all the dependencies are already in the Poetry file. But if we only want to convert a simple notebook, the only thing we need is <code>nbconvert</code> and Python's IpyKernel support:</p> <pre><code>poetry add nbconvert ipykernel\n</code></pre> <p>Now that we have this, we can read the notebook directly from the task and execute it:</p> <pre><code>import os\nimport nbformat\nfrom nbconvert.preprocessors import ExecutePreprocessor, CellExecutionError\n\nprocessor = ExecutePreprocessor(timeout=600, kernel_name=\"python\")\n\n# read the notebook once, as it will never change\nwith open(os.environ.get(\"SCRIPT_PATH\", \"notebook.ipynb\")) as f:\n    notebook = nbformat.read(f, as_version=4)\n\n\ndef execute_notebook() -&gt; str:\n    processor.preprocess(notebook)\n    # the following will raise an CellExecutionError in case of error\n    return nbformat.writes(notebook)\n</code></pre> <p>To convert this into a Celery task, just add the annotation and you are good to go!</p> <p>Why is it better you ask? Well, for one thing, we can now have access to nbconvert's output, including the stacktrace if something goes wrong! Furthermore, any error will raise an exception of type <code>CellExecutionError</code> that will automatically mark Celery's task as a failure.</p> <p>We could even imagine storing the notebook's output itself in the result in case of success. But beware! Depending on the verbosity of the notebook, it may burden the results backend. Up to you! </p>"},{"location":"05-more/","title":"Finishing touches","text":""},{"location":"05-more/#deploying-to-production","title":"Deploying to production","text":"<p>Now that we have everything, the last step is to make our app ready for production.</p> <p>In 2023, wherever you deploy, production usually means one or more docker image, and either a docker-compose, a Helm Chart or some other packaging.</p> <p>I won't go into details here, but have a look at fastapi-notebook-runner for an example of:</p> <ul> <li>a Dockerfile</li> <li>a docker-compose</li> <li>a Helm Chart (Kubernetes).</li> </ul> <p>The full app uses two Docker images even though it needs 3 processes:</p> <ol> <li>the app Docker image, which can launch either celery or fastapi depending on the command argument, and</li> <li>the official redis image.</li> </ol> <p>Again, have a look at fastapi-notebook-runner for more details.</p>"},{"location":"05-more/#tips","title":"Tips","text":"<ul> <li>conventional commits</li> <li>black, ruff   and pytest</li> <li>GitHub Actions</li> <li>MkDocs Material</li> </ul>"},{"location":"05-more/#one-more-thing","title":"One more thing","text":"<p>I really enjoyed putting this site together. If you found it useful, please leave a  on the GitHub repo!</p>"}]}